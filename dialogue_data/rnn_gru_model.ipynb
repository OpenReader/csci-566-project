{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "566 rnn-encoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuTMxecYNdX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4f258f-180e-424a-b7b1-dce8f40a02da"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['至大三上成绩单.pdf',\n",
              " 'BB9E1FA0@D3815A65.36CC2E59',\n",
              " '体检信息登记表.xlsx',\n",
              " 'resume.pdf',\n",
              " '申请信息表--推荐信表格.gdoc',\n",
              " '脚手架.rar',\n",
              " 'Colab Notebooks',\n",
              " 'Resume_xsy_2020_for job.pdf',\n",
              " 'extracted_dialogue.txt',\n",
              " '4000_checkpoint (1).tar',\n",
              " '4000_checkpoint.tar',\n",
              " 'CSCI544 presentation.gdoc',\n",
              " 'xsy_test_result.txt',\n",
              " 'ghc_test_result.txt',\n",
              " 'gru_movie_reply.txt',\n",
              " 'fb_train.json',\n",
              " 'fb_valid.json',\n",
              " 'fb_train',\n",
              " 'gru_fb_reply_13602.txt',\n",
              " 'gru_fb_reply_train_1w.txt',\n",
              " '566 rnn-encoder.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Xe7eXnMeIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "399acf09-237a-4af0-cf5d-6dae411198b5"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "learning_rate = 0.1\n",
        "hidden_size = 256\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name=\"dict\"):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {EOS_token:\"EOS\",SOS_token:\"SOS\"}\n",
        "        self.n_words = 2  \n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)  \n",
        "        self.gru = nn.GRU(hidden_size, hidden_size) \n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1) \n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "def prepareData():\n",
        "    lang_dict = Lang()\n",
        "    sentences = []\n",
        "    max_length=0\n",
        "    with open(\"./extracted_dialogue.txt\",\"r\") as f:\n",
        "        lines = f.read().strip().split(\"\\n\")\n",
        "        for i in range(0, len(lines), 2):\n",
        "            tmp = lines[i].strip()\n",
        "            if len(tmp.split(' ')) > 100:\n",
        "              continue\n",
        "            sentences.append(tmp)\n",
        "            lang_dict.addSentence(tmp)\n",
        "            if len(tmp.split(' ')) > max_length:\n",
        "                max_length = len(tmp.split(' '))\n",
        "    return lang_dict, sentences, max_length\n",
        "\n",
        "def getSentenceTensor(lang, sentence):\n",
        "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
        "    \n",
        "    encoder_hidden = encoder.initHidden() \n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length+1, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  \n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() \n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "def trainIters(encoder, decoder, lang_dict, max_length, sentences,  n_iters, print_every=1000, learning_rate=0.01):\n",
        "    print_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_data = [getSentenceTensor(lang_dict, random.choice(sentences))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        iter_data = training_data[iter - 1]\n",
        "        input_tensor = iter_data\n",
        "        target_tensor = iter_data\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('iter, loss =  (%d %.4f) ' %  (iter,  print_loss_avg))\n",
        "\n",
        "\n",
        "\n",
        "lang_dict, sentences, max_length = prepareData()\n",
        "print(max_length)\n",
        "\n",
        "encoder = EncoderRNN(lang_dict.n_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, lang_dict.n_words).to(device)\n",
        "\n",
        "trainIters(encoder, decoder, lang_dict, max_length, sentences, 10000, print_every=100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4ad75b1bc1e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lowrank\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvd_lowrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_lowrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mConvTranspose1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvTranspose2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvTranspose3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHardtanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTanh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgrad\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboolean_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_overload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Explicitly ask to import `torch.distributed.__init__` first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Otherwise, \"AttributeError: module 'torch' has no attribute 'distributed'\" is raised.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_six\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_source_lines_and_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributed/rpc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorPipeRpcBackendOptions\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend_registry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     from .server_process_global_profiler import (\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0m_server_process_global_profile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributed/rpc/server_process_global_profiler.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m from . import (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgradcheck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradgradcheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgrad_mode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mno_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0manomaly_mode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_anomaly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mnondet_tol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mcheck_undefined_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mcheck_grad_dtypes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m ) -> bool:\n\u001b[1;32m    241\u001b[0m     r\"\"\"Check gradients computed via small finite differences against analytical\n",
            "\u001b[0;32m/usr/lib/python3.6/typing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                                 \" Got %.100r.\" % (args,))\n\u001b[1;32m   1339\u001b[0m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem_inner__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_tp_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/typing.py\u001b[0m in \u001b[0;36m__getitem_inner__\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_type_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_TypingEllipsis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Callable[[arg, ...], result]: each arg must be a type.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/typing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                               \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                               \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__extra__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                               orig_bases=self.__orig_bases__)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/typing.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, bases, namespace, tvars, args, origin, extra, orig_bases)\u001b[0m\n\u001b[1;32m    976\u001b[0m         namespace.update({'__origin__': origin, '__extra__': extra,\n\u001b[1;32m    977\u001b[0m                           '_gorg': None if not origin else origin._gorg})\n\u001b[0;32m--> 978\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         super(GenericMeta, self).__setattr__('_gorg',\n\u001b[1;32m    980\u001b[0m                                              self if not origin else origin._gorg)\n",
            "\u001b[0;32m/usr/lib/python3.6/typing.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, bases, namespace, _root)\u001b[0m\n\u001b[1;32m    135\u001b[0m             raise TypeError(\"Cannot subclass %s\" %\n\u001b[1;32m    136\u001b[0m                             (', '.join(map(_type_repr, bases)) or '()'))\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m                      if getattr(value, \"__isabstractmethod__\", False)}\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__abstractmethods__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__isabstractmethod__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kQif4-iwIFL"
      },
      "source": [
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "MAX_LENGTH = 10  # Maximum sentence length\n",
        "\n",
        "# Default word tokens\n",
        "PAD_token = 0  # Used for padding short sentences\n",
        "SOS_token = 1  # Start-of-sentence token\n",
        "EOS_token = 2  # End-of-sentence token\n",
        "\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "        keep_words = []\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "        # Reinitialize dictionaries\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Count default tokens\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)\n",
        "\n",
        "\n",
        "# Lowercase and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "# Takes string sentence, returns sentence of word indexes\n",
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] if word in voc.word2index else PAD_token for word in sentence.split(' ') ] + [EOS_token]\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # type: (Tensor, Tensor, Optional[Tensor]) -> Tuple[Tensor, Tensor]\n",
        "        # Convert word indexes to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        # Forward pass through GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding\n",
        "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
        "\n",
        "\n",
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden\n",
        "\n",
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, decoder_n_layers):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self._device = device\n",
        "        self._SOS_token = SOS_token\n",
        "        self._decoder_n_layers = decoder_n_layers\n",
        "\n",
        "    __constants__ = ['_device', '_SOS_token', '_decoder_n_layers']\n",
        "\n",
        "    def forward(self, input_seq : torch.Tensor, input_length : torch.Tensor, max_length : int):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:self._decoder_n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=self._device, dtype=torch.long) * self._SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=self._device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CDwguQu0zla"
      },
      "source": [
        "def evaluate(searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words, tokens\n",
        "\n",
        "\n",
        "# Evaluate inputs from user input (stdin)\n",
        "def evaluateInput(searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            input_sentence = input('> ')\n",
        "            # Check if it is quit case\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words,_ = evaluate(searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Bot:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered unknown word.\")\n",
        "\n",
        "# Normalize input sentence and call evaluate()\n",
        "def evaluateExample(sentence, searcher, voc):\n",
        "    print(\"> \" + sentence)\n",
        "    # Normalize sentence\n",
        "    input_sentence = normalizeString(sentence)\n",
        "    # Evaluate sentence\n",
        "    output_words,_ = evaluate(searcher, voc, input_sentence)\n",
        "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "    print('Bot:', ' '.join(output_words))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4vw1FBz3TqE"
      },
      "source": [
        "import math\n",
        "\n",
        "def evaluate_all(pairs, searcher, voc, gram):\n",
        "    ret = []\n",
        "    for s, reply in pairs:\n",
        "        output_words, tokens = evaluate(searcher, voc, s)\n",
        "        reply_tokens = indexesFromSentence(voc, reply)\n",
        "        ret. append((tokens, reply_tokens))\n",
        "    return BLEU(ret, gram)\n",
        "\n",
        "def BLEU(pairs, gram):\n",
        "  accuracy = 0\n",
        "  for tokens, reply_tokens in pairs:\n",
        "      if len(tokens) < gram or len(reply_tokens) < gram:\n",
        "          continue\n",
        "      total = len(tokens) - gram +1\n",
        "      acc = 0\n",
        "      bp = 1\n",
        "      if len(tokens) < len(reply_tokens):\n",
        "          bp *= math.exp(1- (len(tokens)/len(reply_tokens)))\n",
        "      for i in range(len(tokens) - gram + 1 ): \n",
        "          for j in range(len(reply_tokens) - gram +1):\n",
        "              flag = 1\n",
        "              for k in range(gram):\n",
        "                  if tokens[i+k] != reply_tokens[j+k]:\n",
        "                      flag = 0\n",
        "                      break\n",
        "              if flag == 1:\n",
        "                  break\n",
        "          acc += flag\n",
        "      acc /= total\n",
        "      accuracy += bp*acc\n",
        "  accuracy /= len(pairs)\n",
        "  return accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq4yP6nS2opd",
        "outputId": "0778961b-74c5-4a35-d6eb-56ee040271a8"
      },
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
        "\n",
        "def filterPair(p):\n",
        "    # Input sequences need to preserve the last word for EOS token\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def prepareData():\n",
        "    voc = Voc(\"fb\")\n",
        "    with open(\"./fb_train.json\",\"r\") as f:\n",
        "        pairs = json.load(f)\n",
        "        for i in range(len(pairs)):\n",
        "            pairs[i][0] = normalizeString(pairs[i][0])\n",
        "            pairs[i][1] = normalizeString(pairs[i][1])\n",
        "        print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "        pairs = filterPairs(pairs)\n",
        "        print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "        print(\"Counting words...\")\n",
        "        for pair in pairs:\n",
        "            voc.addSentence(pair[0])\n",
        "            voc.addSentence(pair[1])\n",
        "        print(\"Counted words:\", voc.num_words)\n",
        "        return voc, pairs\n",
        "    voc, data = prepareData()\n",
        "\n",
        "save_dir = './fb_train'\n",
        "corpus_name = 'fb'\n",
        "voc, data = prepareData()\n",
        "# Print some pairs to validate\n",
        "print(\"\\npairs:\")\n",
        "for pair in data[:10]:\n",
        "    print(pair)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 218181 sentence pairs\n",
            "Trimmed to 30233 sentence pairs\n",
            "Counting words...\n",
            "Counted words: 6952\n",
            "\n",
            "pairs:\n",
            "['okay but i was published in new yorker once', 'you better not make any spelling mistakes .']\n",
            "['how does that feel for you', 'makes me secure with my manly hobby skills .']\n",
            "['makes me secure with my manly hobby skills .', 'i bet that it does']\n",
            "['i bet that it does', 'anyway . what do you do ?']\n",
            "['anyway . what do you do ?', 'i watch kids for a living']\n",
            "['you work for a funeral home ?', 'yes it is nice halloween is my fav .']\n",
            "['no i don t work at a funeral home', 'ok i see that s your halloween costume']\n",
            "['lol oh i see taught you own it', 'me also what is your favorite ?']\n",
            "['me also what is your favorite ?', 'well i like sherlock holmes and others']\n",
            "['what are you going to school for', 'i m trying to get my ba in finance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5nVZAqVeOsP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KLXOp5YbRow",
        "outputId": "47fa863f-f5db-4db5-c46f-af500c3b6b17"
      },
      "source": [
        "\n",
        "import itertools\n",
        "\n",
        "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    # Trim words used under the MIN_COUNT from the voc\n",
        "    voc.trim(MIN_COUNT)\n",
        "    # Filter out pairs with trimmed words\n",
        "    keep_pairs = []\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "        # Check input sentence\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_input = False\n",
        "                break\n",
        "        # Check output sentence\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "\n",
        "# Trim voc and pairs\n",
        "pairs = trimRareWords(voc, data, MIN_COUNT)\n",
        "\n",
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] if word in voc.word2index else PAD_token for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Returns padded input sequence tensor and lengths\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n",
        "\n",
        "# Example for validation\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keep_words 4769 / 6949 = 0.6863\n",
            "Trimmed from 30233 pairs to 26898, 0.8897 of total\n",
            "input_variable: tensor([[   5,    5,   19,   35,   36],\n",
            "        [ 100,  100,  188,   36,   11],\n",
            "        [4682,  139,   11,   11,  106],\n",
            "        [   4,   54,   75,   36,   36],\n",
            "        [  28,   19,  131,   23,  613],\n",
            "        [4518,  179,  120,  157,  164],\n",
            "        [  46,   11, 2464,   37,   37],\n",
            "        [ 746,   37,   37,    2,    2],\n",
            "        [  18,    2,    2,    0,    0],\n",
            "        [   2,    0,    0,    0,    0]])\n",
            "lengths: tensor([10,  9,  9,  8,  8])\n",
            "target_variable: tensor([[ 142,  247,    5,    5,  132],\n",
            "        [ 162,   81, 2202,  219,  490],\n",
            "        [   5,   36, 1568,  219,    5],\n",
            "        [ 283,   11,   18,   67,  283],\n",
            "        [ 734,   42,  155,  436,   71],\n",
            "        [1391,   37,   65,  436,   91],\n",
            "        [  23,    2,  320,    2,  729],\n",
            "        [1058,    0,   18,    0,   18],\n",
            "        [   2,    0,    2,    0,    2]])\n",
            "mask: tensor([[ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True, False,  True, False,  True],\n",
            "        [ True, False,  True, False,  True]])\n",
            "max_target_len: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0eR2vtxb3CH"
      },
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMEX6HF8lnq8",
        "outputId": "af812798-c5af-4d28-b0b7-91bf088d7fee"
      },
      "source": [
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "# Set checkpoint to load from; set to None if starting from scratch\n",
        "loadFilename = None\n",
        "checkpoint_iter = 4000\n",
        "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "\n",
        "# Load model if a loadFilename is provided\n",
        "if loadFilename:\n",
        "    # If loading on same machine the model was trained on\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "    # If loading a model trained on GPU to CPU\n",
        "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoBdfSqGb7Hq",
        "outputId": "ba402154-8a8c-4234-8457-3f5b5e3ee236"
      },
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for rnn packing should always be on the cpu\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals\n",
        "\n",
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
        "\n",
        "    # Load batches for each iteration\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # Initializations\n",
        "    print('Initializing ...')\n",
        "    start_iteration = 1\n",
        "    print_loss = 0\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Training...\")\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        training_batch = training_batches[iteration - 1]\n",
        "        # Extract fields from batch\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "        # Run a training iteration with batch\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "        print_loss += loss\n",
        "\n",
        "        # Print progress\n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "            print_loss = 0\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (iteration % save_every == 0):\n",
        "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            torch.save({\n",
        "                'iteration': iteration,\n",
        "                'en': encoder.state_dict(),\n",
        "                'de': decoder.state_dict(),\n",
        "                'en_opt': encoder_optimizer.state_dict(),\n",
        "                'de_opt': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc_dict': voc.__dict__,\n",
        "                'embedding': embedding.state_dict()\n",
        "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n",
        "\n",
        "\n",
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 0.8\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 6000\n",
        "print_every = 100\n",
        "save_every = 1000\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "# If you have cuda, configure cuda to call\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "\n",
        "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 100; Percent complete: 1.7%; Average loss: 5.3090\n",
            "Iteration: 200; Percent complete: 3.3%; Average loss: 4.4705\n",
            "Iteration: 300; Percent complete: 5.0%; Average loss: 4.2176\n",
            "Iteration: 400; Percent complete: 6.7%; Average loss: 4.0623\n",
            "Iteration: 500; Percent complete: 8.3%; Average loss: 4.0201\n",
            "Iteration: 600; Percent complete: 10.0%; Average loss: 3.7986\n",
            "Iteration: 700; Percent complete: 11.7%; Average loss: 3.7588\n",
            "Iteration: 800; Percent complete: 13.3%; Average loss: 3.6733\n",
            "Iteration: 900; Percent complete: 15.0%; Average loss: 3.5977\n",
            "Iteration: 1000; Percent complete: 16.7%; Average loss: 3.4615\n",
            "Iteration: 1100; Percent complete: 18.3%; Average loss: 3.3652\n",
            "Iteration: 1200; Percent complete: 20.0%; Average loss: 3.2782\n",
            "Iteration: 1300; Percent complete: 21.7%; Average loss: 3.2308\n",
            "Iteration: 1400; Percent complete: 23.3%; Average loss: 3.3545\n",
            "Iteration: 1500; Percent complete: 25.0%; Average loss: 3.1301\n",
            "Iteration: 1600; Percent complete: 26.7%; Average loss: 3.0594\n",
            "Iteration: 1700; Percent complete: 28.3%; Average loss: 2.9569\n",
            "Iteration: 1800; Percent complete: 30.0%; Average loss: 2.9869\n",
            "Iteration: 1900; Percent complete: 31.7%; Average loss: 2.8361\n",
            "Iteration: 2000; Percent complete: 33.3%; Average loss: 2.7441\n",
            "Iteration: 2100; Percent complete: 35.0%; Average loss: 2.6484\n",
            "Iteration: 2200; Percent complete: 36.7%; Average loss: 2.5909\n",
            "Iteration: 2300; Percent complete: 38.3%; Average loss: 2.5602\n",
            "Iteration: 2400; Percent complete: 40.0%; Average loss: 2.5018\n",
            "Iteration: 2500; Percent complete: 41.7%; Average loss: 2.5257\n",
            "Iteration: 2600; Percent complete: 43.3%; Average loss: 2.2206\n",
            "Iteration: 2700; Percent complete: 45.0%; Average loss: 2.3631\n",
            "Iteration: 2800; Percent complete: 46.7%; Average loss: 2.3801\n",
            "Iteration: 2900; Percent complete: 48.3%; Average loss: 2.1555\n",
            "Iteration: 3000; Percent complete: 50.0%; Average loss: 2.0986\n",
            "Iteration: 3100; Percent complete: 51.7%; Average loss: 1.9871\n",
            "Iteration: 3200; Percent complete: 53.3%; Average loss: 1.9821\n",
            "Iteration: 3300; Percent complete: 55.0%; Average loss: 1.8939\n",
            "Iteration: 3400; Percent complete: 56.7%; Average loss: 1.7625\n",
            "Iteration: 3500; Percent complete: 58.3%; Average loss: 1.6220\n",
            "Iteration: 3600; Percent complete: 60.0%; Average loss: 1.5448\n",
            "Iteration: 3700; Percent complete: 61.7%; Average loss: 1.7507\n",
            "Iteration: 3800; Percent complete: 63.3%; Average loss: 1.5743\n",
            "Iteration: 3900; Percent complete: 65.0%; Average loss: 1.4656\n",
            "Iteration: 4000; Percent complete: 66.7%; Average loss: 1.4707\n",
            "Iteration: 4100; Percent complete: 68.3%; Average loss: 1.4564\n",
            "Iteration: 4200; Percent complete: 70.0%; Average loss: 1.2151\n",
            "Iteration: 4300; Percent complete: 71.7%; Average loss: 1.2051\n",
            "Iteration: 4400; Percent complete: 73.3%; Average loss: 1.4185\n",
            "Iteration: 4500; Percent complete: 75.0%; Average loss: 1.2541\n",
            "Iteration: 4600; Percent complete: 76.7%; Average loss: 1.2245\n",
            "Iteration: 4700; Percent complete: 78.3%; Average loss: 1.1830\n",
            "Iteration: 4800; Percent complete: 80.0%; Average loss: 1.1386\n",
            "Iteration: 4900; Percent complete: 81.7%; Average loss: 1.2255\n",
            "Iteration: 5000; Percent complete: 83.3%; Average loss: 0.9652\n",
            "Iteration: 5100; Percent complete: 85.0%; Average loss: 1.0607\n",
            "Iteration: 5200; Percent complete: 86.7%; Average loss: 1.0205\n",
            "Iteration: 5300; Percent complete: 88.3%; Average loss: 0.9060\n",
            "Iteration: 5400; Percent complete: 90.0%; Average loss: 0.8988\n",
            "Iteration: 5500; Percent complete: 91.7%; Average loss: 0.8164\n",
            "Iteration: 5600; Percent complete: 93.3%; Average loss: 0.7566\n",
            "Iteration: 5700; Percent complete: 95.0%; Average loss: 0.7044\n",
            "Iteration: 5800; Percent complete: 96.7%; Average loss: 0.6286\n",
            "Iteration: 5900; Percent complete: 98.3%; Average loss: 0.6810\n",
            "Iteration: 6000; Percent complete: 100.0%; Average loss: 0.7073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhMNDDk2chzC"
      },
      "source": [
        "\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 1\n",
        "iter_num = 400\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, voc):\n",
        "    \n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in input_tensor])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(input_tensor)\n",
        "    input_batch = input_batch.transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "\n",
        "\n",
        "    # Forward input through encoder model\n",
        "    encoder_outputs, encoder_hidden = encoder(input_batch, lengths)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "    # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "    # Initialize decoder input with SOS_token\n",
        "    decoder_outputs = torch.zeros([0], device=device)\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    for di in range(MAX_LENGTH):\n",
        "        # Forward pass through decoder\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "        decoder_outputs = torch.cat((decoder_outputs, decoder_output), 0)\n",
        "        decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "        if decoder_input == EOS_token:\n",
        "            break\n",
        "        decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "\n",
        "    for i in range(len(target_tensor), decoder_outputs.shape[0]):\n",
        "        target_tensor.append(PAD_token)\n",
        "    target_tensor = torch.tensor(target_tensor[:decoder_outputs.shape[0]], device = device).reshape(-1)\n",
        "\n",
        "    loss = criterion(decoder_outputs, target_tensor)\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / MAX_LENGTH\n",
        "\n",
        "\n",
        "def trainIters(encoder, decoder, voc, data, batch_size, n_iters, print_every=1000, learning_rate=0.01):\n",
        "    print_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters())\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters())\n",
        "    criterion= nn.CrossEntropyLoss()\n",
        "\n",
        "    cnt = 0\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        random.shuffle(data)\n",
        "\n",
        "        for s1,s2 in data:\n",
        "            s1 = indexesFromSentence(voc, s1)\n",
        "            s2 = indexesFromSentence(voc, s2)\n",
        "\n",
        "            loss = train([s1], s2, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, voc)\n",
        "\n",
        "            cnt += 1\n",
        "            if cnt % print_every == 0:\n",
        "                print('iter, loss =  (%d %.4f) ' %  (iter,  loss))\n",
        "\n",
        "\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "trainIters(encoder, decoder, voc, data, batch_size, iter_num, print_every=1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lehM2I0IxBQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6991691-7adc-4ff8-da6f-ed6abae968b3"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set dropout layers to eval mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder, decoder.n_layers)\n",
        "\n",
        "\n",
        "# with open(\"./fb_train.json\",\"r\") as f:\n",
        "#     train_data = json.load(f)\n",
        "#     for i in range(len(train_data)):\n",
        "#         train_data[i][0] = normalizeString(train_data[i][0])\n",
        "#         train_data[i][1] = normalizeString(train_data[i][1])\n",
        "# print(len(train_data))\n",
        "\n",
        "# random.shuffle(data)\n",
        "\n",
        "# my_reply = \"\"\n",
        "\n",
        "# for input_sentence,reply in data[:10000]:\n",
        "#     output_words,_ = evaluate(scripted_searcher, voc, input_sentence)\n",
        "#     output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "#     # print(input_sentence)\n",
        "#     # print(' '.join(output_words))\n",
        "#     # print()\n",
        "#     my_reply +=' '.join(output_words) +'\\n'\n",
        "\n",
        "# with open(\"./gru_fb_reply_train_1w.txt\",\"w\") as f:\n",
        "#   f.write(my_reply)\n",
        "\n",
        "# with open(\"./ghc_test_result.txt\",\"r\") as f:\n",
        "#     pairs = []\n",
        "#     max_length=0\n",
        "#     lines = f.read().strip().split(\"\\n\")\n",
        "#     for i in range(0, len(lines), 3):\n",
        "#             tmp = lines[i].strip()\n",
        "#             tmp = normalizeString(tmp)\n",
        "#             tmp1 = lines[i+1].strip()\n",
        "#             tmp1 = normalizeString(tmp1)\n",
        "#             pairs.append((indexesFromSentence(voc, tmp1), indexesFromSentence(voc, tmp)))\n",
        "# accuracy = BLEU(pairs, 1)\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 1))\n",
        "# accuracy = BLEU(pairs, 2)\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 2))\n",
        "# accuracy = BLEU(pairs, 3)\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 3))\n",
        "# accuracy = BLEU(pairs, 4)\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 4))\n",
        "\n",
        "\n",
        "# accuracy = evaluate_all(pairs[-1000:], scripted_searcher, voc, 1)\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 1))\n",
        "# accuracy = evaluate_all(pairs[-1000:], scripted_searcher, voc, 2)\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 2))\n",
        "# accuracy = evaluate_all(pairs[-1000:], scripted_searcher, voc, 3)april29\n",
        "\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 3))\n",
        "# accuracy = evaluate_all(pairs[-1000:], scripted_searcher, voc, 4)\n",
        "# print(\"accuracy is {}% for {}-gram \".format(accuracy*100, 4))\n",
        "\n",
        "# random.shuffle(pairs)\n",
        "\n",
        "# for s, r in pairs[:10]:\n",
        "#     evaluateExample(s, scripted_searcher, voc)\n",
        "\n",
        "\n",
        "# Evaluate examples\n",
        "sentences = [\"boss i need a rise\", \"what's up?\", \"who are you?\", \n",
        "             \"where am I?\", \"where are you from?\", \"okay give me the keys .\", \n",
        "             \"hello what are doing today ?\", \"i just got done watching a horror movie\",\n",
        "             \"hi ! how are you doing tonight ?\", \"i work in a homeless shelter in my town .\",\n",
        "             \"i love the crowds , getting to know people .\", \"that nobel prize will just have to wait .\",\n",
        "             \"you got a name ?\",\"i love spending time with my family\", \"so what do you do now for fun ? i like to read .\",\n",
        "             \"wanna kiss me jim ?\", \"i've a dream , it is to work from home\", \"i make time stop . i've a superpower.\", \n",
        "             \"i don't like blood. i faint when i see blood.\", \"hi ! do you like turtles ?\"]\n",
        "for s in sentences:\n",
        "    evaluateExample(s, searcher, voc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> boss i need a rise\n",
            "Bot: do you mean help you ?\n",
            "> what's up?\n",
            "Bot: nothing much . do you hunt ?\n",
            "> who are you?\n",
            "Bot: lol i m you\n",
            "> where am I?\n",
            "Bot: i am in new york area\n",
            "> where are you from?\n",
            "Bot: i am from illinois west side of chicago .\n",
            "> okay give me the keys .\n",
            "Bot: i guess what does that not\n",
            "> hello what are doing today ?\n",
            "Bot: i m not really i m doing great hp\n",
            "> i just got done watching a horror movie\n",
            "Bot: what movie are you watching ? movie\n",
            "> hi ! how are you doing tonight ?\n",
            "Bot: i m good thanks for asking\n",
            "> i work in a homeless shelter in my town .\n",
            "Bot: nice do you have any hobbies ?\n",
            "> i love the crowds , getting to know people .\n",
            "Bot: where is your favorite part\n",
            "> that nobel prize will just have to wait .\n",
            "Bot: and what do you do ?\n",
            "> you got a name ?\n",
            "Bot: yes ! is your name name ?\n",
            "> i love spending time with my family\n",
            "Bot: i like playing the guitar in my free time\n",
            "> so what do you do now for fun ? i like to read .\n",
            "Bot: i love reading . my book is\n",
            "> wanna kiss me jim ?\n",
            "Bot: if you are a good time !\n",
            "> i've a dream , it is to work from home\n",
            "Bot: nice ! my girlfriend is an awesome\n",
            "> i make time stop . i've a superpower.\n",
            "Bot: oh i see is a crazy animal\n",
            "> i don't like blood. i faint when i see blood.\n",
            "Bot: oh ok . i do not have . .\n",
            "> hi ! do you like turtles ?\n",
            "Bot: i do not know what about\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylhdf0PPXTl_",
        "outputId": "ae5c9330-62df-4673-c9e4-c8636f6bd73f"
      },
      "source": [
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "corpus_name = \"cornell movie-dialogs corpus\"\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "# If you're loading your own model\n",
        "# Set checkpoint to load from\n",
        "checkpoint_iter = 4000\n",
        "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                             '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                             '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "# If you're loading the hosted model\n",
        "loadFilename = './4000_checkpoint.tar'\n",
        "\n",
        "# Load model\n",
        "# Force CPU device options (to match tensors in this tutorial)\n",
        "checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "encoder_sd = checkpoint['en']\n",
        "decoder_sd = checkpoint['de']\n",
        "encoder_optimizer_sd = checkpoint['en_opt']\n",
        "decoder_optimizer_sd = checkpoint['de_opt']\n",
        "embedding_sd = checkpoint['embedding']\n",
        "voc = Voc(corpus_name)\n",
        "voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "# Load trained model params\n",
        "encoder.load_state_dict(encoder_sd)\n",
        "decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "# Set dropout layers to eval mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "print('Models built and ready to go!')\n",
        "\n",
        "### Compile the whole greedy search model to TorchScript model\n",
        "# Create artificial inputs\n",
        "test_seq = torch.LongTensor(MAX_LENGTH, 1).random_(0, voc.num_words).to(device)\n",
        "test_seq_length = torch.LongTensor([test_seq.size()[0]]).to(device)\n",
        "# Trace the model\n",
        "traced_encoder = torch.jit.trace(encoder, (test_seq, test_seq_length))\n",
        "\n",
        "### Convert decoder model\n",
        "# Create and generate artificial inputs\n",
        "test_encoder_outputs, test_encoder_hidden = traced_encoder(test_seq, test_seq_length)\n",
        "test_decoder_hidden = test_encoder_hidden[:decoder.n_layers]\n",
        "test_decoder_input = torch.LongTensor(1, 1).random_(0, voc.num_words)\n",
        "# Trace the model\n",
        "traced_decoder = torch.jit.trace(decoder, (test_decoder_input, test_decoder_hidden, test_encoder_outputs))\n",
        "\n",
        "### Initialize searcher module by wrapping ``torch.jit.script`` call\n",
        "scripted_searcher = torch.jit.script(GreedySearchDecoder(traced_encoder, traced_decoder, decoder.n_layers))\n",
        "\n",
        "# Use appropriate device\n",
        "scripted_searcher.to(device)\n",
        "# Set dropout layers to eval mode\n",
        "scripted_searcher.eval()\n",
        "\n",
        "# Evaluate examples\n",
        "sentences = [\"boss i need a rise\", \"what's up?\", \"who are you?\", \n",
        "             \"where am I?\", \"where are you from?\", \"okay give me the keys .\", \n",
        "             \"hello what are doing today ?\", \"i just got done watching a horror movie\",\n",
        "             \"hi ! how are you doing tonight ?\", \"i work in a homeless shelter in my town .\",\n",
        "             \"i love the crowds , getting to know people .\", \"that nobel prize will just have to wait .\",\n",
        "             \"you got a name ?\",\"i love spending time with my family\", \"so what do you do now for fun ? i like to read .\",\n",
        "             \"wanna kiss me jim ?\", \"i've a dream , it is to work from home\", \"i make time stop . i've a superpower.\", \n",
        "             \"i don't like blood. i faint when i see blood.\", \"hi ! do you like turtles ?\"]\n",
        "for s in sentences:\n",
        "    evaluateExample(s, scripted_searcher, voc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/jit/_trace.py:152: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  if a.grad is not None:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> boss i need a rise\n",
            "Bot: you re a good loser .\n",
            "> what's up?\n",
            "Bot: i m going to get my car .\n",
            "> who are you?\n",
            "Bot: i m the owner .\n",
            "> where am I?\n",
            "Bot: in the house .\n",
            "> where are you from?\n",
            "Bot: south america .\n",
            "> okay give me the keys .\n",
            "Bot: what is it ?\n",
            "> hello what are doing today ?\n",
            "Bot: i m thirsty .\n",
            "> i just got done watching a horror movie\n",
            "Bot: you re not supposed to .\n",
            "> hi ! how are you doing tonight ?\n",
            "Bot: i m fine .\n",
            "> i work in a homeless shelter in my town .\n",
            "Bot: i m sorry .\n",
            "> i love the crowds , getting to know people .\n",
            "Bot: i know .\n",
            "> that nobel prize will just have to wait .\n",
            "Bot: i ll be there for you .\n",
            "> you got a name ?\n",
            "Bot: i m a psychiatrist .\n",
            "> i love spending time with my family\n",
            "Bot: i ll get it for you .\n",
            "> so what do you do now for fun ? i like to read .\n",
            "Bot: you want to know what you want ?\n",
            "> wanna kiss me jim ?\n",
            "Bot: yes .\n",
            "> i've a dream , it is to work from home\n",
            "Bot: i m not sure .\n",
            "> i make time stop . i've a superpower.\n",
            "Bot: you re not supposed to .\n",
            "> i don't like blood. i faint when i see blood.\n",
            "Bot: i ll take it .\n",
            "> hi ! do you like turtles ?\n",
            "Bot: not at all .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}