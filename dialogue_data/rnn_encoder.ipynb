{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuTMxecYNdX5",
        "outputId": "dedbd1b5-702d-4cb6-a0ca-c4debe0916ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['至大三上成绩单.pdf',\n",
              " 'BB9E1FA0@D3815A65.36CC2E59',\n",
              " '体检信息登记表.xlsx',\n",
              " 'resume.pdf',\n",
              " '申请信息表--推荐信表格.gdoc',\n",
              " '脚手架.rar',\n",
              " 'Colab Notebooks',\n",
              " 'Resume_xsy_2020_for job.pdf',\n",
              " 'Untitled0.ipynb',\n",
              " 'extracted_dialogue.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Xe7eXnMeIe",
        "outputId": "227f5229-ef8a-46ee-fc4d-4c856b754815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "learning_rate = 0.1\n",
        "hidden_size = 256\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name=\"dict\"):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {EOS_token:\"EOS\",SOS_token:\"SOS\"}\n",
        "        self.n_words = 2  \n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)  \n",
        "        self.gru = nn.GRU(hidden_size, hidden_size) \n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1) \n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "def prepareData():\n",
        "    lang_dict = Lang()\n",
        "    sentences = []\n",
        "    max_length=0\n",
        "    with open(\"./extracted_dialogue.txt\",\"r\") as f:\n",
        "        lines = f.read().strip().split(\"\\n\")\n",
        "        for i in range(0, len(lines), 2):\n",
        "            tmp = lines[i].strip()\n",
        "            sentences.append(tmp)\n",
        "            lang_dict.addSentence(tmp)\n",
        "            if len(tmp) > max_length:\n",
        "                max_length = len(tmp)\n",
        "    return lang_dict, sentences, max_length\n",
        "\n",
        "def getSentenceTensor(lang, sentence):\n",
        "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
        "    \n",
        "    encoder_hidden = encoder.initHidden() \n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  \n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() \n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "\n",
        "def trainIters(encoder, decoder, lang_dict, max_length, sentences,  n_iters, print_every=1000, learning_rate=0.01):\n",
        "    print_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_data = [getSentenceTensor(lang_dict, random.choice(sentences))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        iter_data = training_data[iter - 1]\n",
        "        input_tensor = iter_data\n",
        "        target_tensor = iter_data\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('iter, loss =  (%d %.4f) ' %  (iter,  print_loss_avg))\n",
        "\n",
        "\n",
        "\n",
        "lang_dict, sentences, max_length = prepareData()\n",
        "print(max_length)\n",
        "\n",
        "encoder = EncoderRNN(lang_dict.n_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, lang_dict.n_words).to(device)\n",
        "\n",
        "trainIters(encoder, decoder, lang_dict, max_length, sentences, 10000, print_every=100)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1903\n",
            "iter, loss =  (100 6.7820) \n",
            "iter, loss =  (200 7.1964) \n",
            "iter, loss =  (300 5.9220) \n",
            "iter, loss =  (400 5.9519) \n",
            "iter, loss =  (500 5.7178) \n",
            "iter, loss =  (600 6.0532) \n",
            "iter, loss =  (700 6.3610) \n",
            "iter, loss =  (800 6.2912) \n",
            "iter, loss =  (900 6.0389) \n",
            "iter, loss =  (1000 6.1918) \n",
            "iter, loss =  (1100 5.8251) \n",
            "iter, loss =  (1200 5.4222) \n",
            "iter, loss =  (1300 6.1846) \n",
            "iter, loss =  (1400 5.3709) \n",
            "iter, loss =  (1500 5.9080) \n",
            "iter, loss =  (1600 5.9293) \n",
            "iter, loss =  (1700 5.0843) \n",
            "iter, loss =  (1800 6.1497) \n",
            "iter, loss =  (1900 5.8890) \n",
            "iter, loss =  (2000 5.2503) \n",
            "iter, loss =  (2100 5.8960) \n",
            "iter, loss =  (2200 5.9615) \n",
            "iter, loss =  (2300 5.8921) \n",
            "iter, loss =  (2400 5.4792) \n",
            "iter, loss =  (2500 5.1385) \n",
            "iter, loss =  (2600 5.5372) \n",
            "iter, loss =  (2700 5.8608) \n",
            "iter, loss =  (2800 5.5288) \n",
            "iter, loss =  (2900 5.3126) \n",
            "iter, loss =  (3000 5.9882) \n",
            "iter, loss =  (3100 5.3571) \n",
            "iter, loss =  (3200 5.2260) \n",
            "iter, loss =  (3300 5.5278) \n",
            "iter, loss =  (3400 5.1773) \n",
            "iter, loss =  (3500 5.5881) \n",
            "iter, loss =  (3600 5.9069) \n",
            "iter, loss =  (3700 5.4209) \n",
            "iter, loss =  (3800 5.7328) \n",
            "iter, loss =  (3900 5.2401) \n",
            "iter, loss =  (4000 5.7082) \n",
            "iter, loss =  (4100 5.2158) \n",
            "iter, loss =  (4200 5.2828) \n",
            "iter, loss =  (4300 6.0313) \n",
            "iter, loss =  (4400 5.8119) \n",
            "iter, loss =  (4500 5.7117) \n",
            "iter, loss =  (4600 6.4188) \n",
            "iter, loss =  (4700 4.9496) \n",
            "iter, loss =  (4800 5.2920) \n",
            "iter, loss =  (4900 5.7999) \n",
            "iter, loss =  (5000 5.5644) \n",
            "iter, loss =  (5100 6.0049) \n",
            "iter, loss =  (5200 5.9011) \n",
            "iter, loss =  (5300 6.6119) \n",
            "iter, loss =  (5400 5.7954) \n",
            "iter, loss =  (5500 5.9148) \n",
            "iter, loss =  (5600 5.7859) \n",
            "iter, loss =  (5700 5.3337) \n",
            "iter, loss =  (5800 5.6854) \n",
            "iter, loss =  (5900 5.6940) \n",
            "iter, loss =  (6000 5.2734) \n",
            "iter, loss =  (6100 5.1599) \n",
            "iter, loss =  (6200 5.5673) \n",
            "iter, loss =  (6300 5.6080) \n",
            "iter, loss =  (6400 5.6042) \n",
            "iter, loss =  (6500 5.8070) \n",
            "iter, loss =  (6600 5.5329) \n",
            "iter, loss =  (6700 5.4497) \n",
            "iter, loss =  (6800 5.7508) \n",
            "iter, loss =  (6900 5.6403) \n",
            "iter, loss =  (7000 5.8054) \n",
            "iter, loss =  (7100 5.4233) \n",
            "iter, loss =  (7200 5.2174) \n",
            "iter, loss =  (7300 5.6727) \n",
            "iter, loss =  (7400 5.8655) \n",
            "iter, loss =  (7500 5.7658) \n",
            "iter, loss =  (7600 5.3843) \n",
            "iter, loss =  (7700 5.6181) \n",
            "iter, loss =  (7800 5.4123) \n",
            "iter, loss =  (7900 5.8246) \n",
            "iter, loss =  (8000 5.7934) \n",
            "iter, loss =  (8100 5.7729) \n",
            "iter, loss =  (8200 5.6013) \n",
            "iter, loss =  (8300 5.7206) \n",
            "iter, loss =  (8400 5.4058) \n",
            "iter, loss =  (8500 5.1916) \n",
            "iter, loss =  (8600 5.5043) \n",
            "iter, loss =  (8700 5.5405) \n",
            "iter, loss =  (8800 5.5546) \n",
            "iter, loss =  (8900 5.3868) \n",
            "iter, loss =  (9000 5.0621) \n",
            "iter, loss =  (9100 5.4756) \n",
            "iter, loss =  (9200 5.5661) \n",
            "iter, loss =  (9300 5.3524) \n",
            "iter, loss =  (9400 5.4640) \n",
            "iter, loss =  (9500 5.2505) \n",
            "iter, loss =  (9600 5.0248) \n",
            "iter, loss =  (9700 5.6639) \n",
            "iter, loss =  (9800 5.8115) \n",
            "iter, loss =  (9900 5.4799) \n",
            "iter, loss =  (10000 5.2541) \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}